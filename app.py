#!/usr/bin/env python3
"""
å³æ™‚ç¿»è­¯ç³»çµ± Flask æ‡‰ç”¨
Real-time Translation System Flask App
"""

from flask import Flask, render_template, request, jsonify
import openai
import tempfile
import os
import hashlib
import time
import threading
from functools import lru_cache

app = Flask(__name__)

# ç¿»è­¯å¿«å–å’Œä¸¦ç™¼æ§åˆ¶
translation_cache = {}
cache_lock = threading.Lock()
active_translations = {}
MAX_CACHE_SIZE = 1000
CACHE_EXPIRY = 3600  # 1å°æ™‚

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/transcribe', methods=['POST'])
def transcribe_audio():
    """ä½¿ç”¨ OpenAI Whisper API è½‰éŒ„éŸ³é »"""
    try:
        # æª¢æŸ¥è«‹æ±‚ä¸­æ˜¯å¦æœ‰éŸ³é »æ–‡ä»¶
        if 'audio' not in request.files:
            return jsonify({'error': 'æ²’æœ‰æ‰¾åˆ°éŸ³é »æ–‡ä»¶'}), 400
        
        audio_file = request.files['audio']
        api_key = request.form.get('api_key', '')
        language = request.form.get('language', 'auto')
        
        if not api_key:
            return jsonify({'error': 'è«‹æä¾› OpenAI API Key'}), 400
            
        if audio_file.filename == '':
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        # è¨­ç½® OpenAI API key
        openai.api_key = api_key
        
        # æ ¹æ“šæ–‡ä»¶é¡å‹æ±ºå®šæ“´å±•å
        file_extension = '.webm'  # é è¨­
        if audio_file.filename:
            if audio_file.filename.endswith('.mp4'):
                file_extension = '.mp4'
            elif audio_file.filename.endswith('.wav'):
                file_extension = '.wav'
            elif audio_file.filename.endswith('.m4a'):
                file_extension = '.m4a'
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶ä¿å­˜éŸ³é »
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            audio_file.save(temp_file.name)
            temp_file_path = temp_file.name
        
        try:
            # ä½¿ç”¨ OpenAI Whisper API è½‰éŒ„
            with open(temp_file_path, 'rb') as audio:
                if language == 'auto':
                    transcript = openai.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio,
                        response_format="text"
                    )
                else:
                    # èªè¨€ç¢¼æ˜ å°„
                    lang_map = {
                        'zh-TW': 'zh',
                        'en-US': 'en'
                    }
                    transcript = openai.audio.transcriptions.create(
                        model="whisper-1", 
                        file=audio,
                        language=lang_map.get(language, language),
                        response_format="text"
                    )
            
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            os.unlink(temp_file_path)
            
            return jsonify({
                'success': True,
                'text': transcript.strip() if hasattr(transcript, 'strip') else str(transcript).strip()
            })
            
        except Exception as e:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
            return jsonify({'error': f'Whisper è½‰éŒ„å¤±æ•—: {str(e)}'}), 500
            
    except Exception as e:
        return jsonify({'error': f'æœå‹™å™¨éŒ¯èª¤: {str(e)}'}), 500

def generate_cache_key(text, target_language, source_language):
    """ç”Ÿæˆå¿«å–éµå€¼"""
    content = f"{text}|{target_language}|{source_language}"
    return hashlib.md5(content.encode('utf-8')).hexdigest()

def clean_cache():
    """æ¸…ç†éæœŸå¿«å–"""
    current_time = time.time()
    with cache_lock:
        expired_keys = [
            key for key, (_, timestamp) in translation_cache.items()
            if current_time - timestamp > CACHE_EXPIRY
        ]
        for key in expired_keys:
            del translation_cache[key]

def get_from_cache(cache_key):
    """å¾å¿«å–ç²å–ç¿»è­¯çµæœ"""
    with cache_lock:
        if cache_key in translation_cache:
            translation, timestamp = translation_cache[cache_key]
            if time.time() - timestamp < CACHE_EXPIRY:
                return translation
            else:
                del translation_cache[cache_key]
    return None

def save_to_cache(cache_key, translation):
    """ä¿å­˜ç¿»è­¯çµæœåˆ°å¿«å–"""
    with cache_lock:
        # é™åˆ¶å¿«å–å¤§å°
        if len(translation_cache) >= MAX_CACHE_SIZE:
            # åˆªé™¤æœ€èˆŠçš„æ¢ç›®
            oldest_key = min(translation_cache.keys(), 
                            key=lambda k: translation_cache[k][1])
            del translation_cache[oldest_key]
        
        translation_cache[cache_key] = (translation, time.time())

def validate_translation_request(data):
    """é©—è­‰ç¿»è­¯è«‹æ±‚"""
    if not data:
        return False, 'æ²’æœ‰æ‰¾åˆ° JSON æ•¸æ“š'
    
    text = data.get('text', '').strip()
    api_key = data.get('api_key', '')
    
    if not text:
        return False, 'è«‹æä¾›è¦ç¿»è­¯çš„æ–‡å­—'
    
    if len(text) > 5000:
        return False, 'æ–‡å­—é•·åº¦ä¸èƒ½è¶…é 5000 å­—ç¬¦'
    
    if not api_key:
        return False, 'è«‹æä¾› OpenAI API Key'
    
    return True, None

def optimize_translation_prompt(text, target_language, source_language):
    """å„ªåŒ–ç¿»è­¯æç¤ºè©"""
    # èªè¨€æ˜ å°„ï¼Œå„ªåŒ–æç¤ºè©
    language_map = {
        'ç¹é«”ä¸­æ–‡': 'Traditional Chinese',
        'ç°¡é«”ä¸­æ–‡': 'Simplified Chinese', 
        'è‹±æ–‡': 'English',
        'æ—¥æ–‡': 'Japanese',
        'éŸ“æ–‡': 'Korean',
        'auto': 'auto-detect'
    }
    
    target_lang = language_map.get(target_language, target_language)
    source_lang = language_map.get(source_language, source_language)
    
    if source_language == 'auto':
        system_prompt = f"You are a professional translator. Translate the following text to {target_lang}. Maintain the original tone and context. Return only the translation without explanations."
        user_prompt = text
    else:
        system_prompt = f"You are a professional translator. Translate the following {source_lang} text to {target_lang}. Maintain the original tone and context. Return only the translation without explanations."
        user_prompt = text
    
    return system_prompt, user_prompt

@app.route('/translate', methods=['POST'])
def translate_text():
    """é‡æ§‹çš„ç¿»è­¯ç«¯é» - æ”¯æ´å¿«å–ã€ä¸¦ç™¼æ§åˆ¶ã€éŒ¯èª¤è™•ç†"""
    start_time = time.time()
    
    try:
        # æ¸…ç†éæœŸå¿«å–
        if len(translation_cache) > 0:
            clean_cache()
        
        # ç²å–å’Œé©—è­‰è«‹æ±‚æ•¸æ“š
        data = request.get_json()
        is_valid, error_msg = validate_translation_request(data)
        
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg,
                'processing_time': round((time.time() - start_time) * 1000, 2)
            }), 400
        
        text = data.get('text', '').strip()
        target_language = data.get('target_language', 'ç¹é«”ä¸­æ–‡')
        source_language = data.get('source_language', 'auto')
        api_key = data.get('api_key', '')
        
        # ç”Ÿæˆå¿«å–éµå€¼
        cache_key = generate_cache_key(text, target_language, source_language)
        
        # æª¢æŸ¥å¿«å–
        cached_translation = get_from_cache(cache_key)
        if cached_translation:
            return jsonify({
                'success': True,
                'translation': cached_translation,
                'source_text': text,
                'target_language': target_language,
                'source_language': source_language,
                'from_cache': True,
                'processing_time': round((time.time() - start_time) * 1000, 2)
            })
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ç›¸åŒè«‹æ±‚æ­£åœ¨è™•ç†ï¼ˆé˜²é‡è¤‡è«‹æ±‚ï¼‰
        if cache_key in active_translations:
            return jsonify({
                'success': False,
                'error': 'ç›¸åŒçš„ç¿»è­¯è«‹æ±‚æ­£åœ¨è™•ç†ä¸­ï¼Œè«‹ç¨å¾Œ',
                'processing_time': round((time.time() - start_time) * 1000, 2)
            }), 429
        
        # æ¨™è¨˜è«‹æ±‚ç‚ºè™•ç†ä¸­
        active_translations[cache_key] = True
        
        try:
            # è¨­ç½® OpenAI API key
            openai.api_key = api_key
            
            # å„ªåŒ–ç¿»è­¯æç¤ºè©
            system_prompt, user_prompt = optimize_translation_prompt(
                text, target_language, source_language
            )
            
            # èª¿ç”¨ OpenAI API
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,
                temperature=0.1,  # é™ä½æº«åº¦æé«˜ä¸€è‡´æ€§
                timeout=30  # 30ç§’è¶…æ™‚
            )
            
            translation = response.choices[0].message.content.strip()
            
            # ä¿å­˜åˆ°å¿«å–
            save_to_cache(cache_key, translation)
            
            return jsonify({
                'success': True,
                'translation': translation,
                'source_text': text,
                'target_language': target_language,
                'source_language': source_language,
                'from_cache': False,
                'processing_time': round((time.time() - start_time) * 1000, 2),
                'cache_size': len(translation_cache)
            })
            
        finally:
            # æ¸…é™¤è™•ç†ä¸­æ¨™è¨˜
            active_translations.pop(cache_key, None)
            
    except openai.RateLimitError:
        return jsonify({
            'success': False,
            'error': 'API è«‹æ±‚é »ç‡é™åˆ¶ï¼Œè«‹ç¨å¾Œå†è©¦',
            'processing_time': round((time.time() - start_time) * 1000, 2)
        }), 429
        
    except openai.AuthenticationError:
        return jsonify({
            'success': False,
            'error': 'API Key ç„¡æ•ˆï¼Œè«‹æª¢æŸ¥æ‚¨çš„ OpenAI API Key',
            'processing_time': round((time.time() - start_time) * 1000, 2)
        }), 401
        
    except openai.APITimeoutError:
        return jsonify({
            'success': False,
            'error': 'è«‹æ±‚è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦',
            'processing_time': round((time.time() - start_time) * 1000, 2)
        }), 408
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ç¿»è­¯å¤±æ•—: {str(e)}',
            'processing_time': round((time.time() - start_time) * 1000, 2)
        }), 500

@app.route('/translate/status', methods=['GET'])
def translation_status():
    """ç²å–ç¿»è­¯æœå‹™ç‹€æ…‹"""
    clean_cache()  # æ¸…ç†éæœŸå¿«å–
    
    return jsonify({
        'cache_size': len(translation_cache),
        'max_cache_size': MAX_CACHE_SIZE,
        'cache_expiry_seconds': CACHE_EXPIRY,
        'active_translations': len(active_translations),
        'uptime': time.time(),
        'cache_hit_rate': round(len(translation_cache) / max(1, len(translation_cache) + len(active_translations)) * 100, 2)
    })

@app.route('/translate/clear-cache', methods=['POST'])
def clear_translation_cache():
    """æ¸…é™¤ç¿»è­¯å¿«å–"""
    with cache_lock:
        translation_cache.clear()
        active_translations.clear()
    
    return jsonify({
        'success': True,
        'message': 'ç¿»è­¯å¿«å–å·²æ¸…é™¤',
        'cache_size': 0
    })

if __name__ == '__main__':
    try:
        print("ğŸ—£ï¸ å³æ™‚ç¿»è­¯ç³»çµ±å•Ÿå‹•ä¸­...")
        print("ğŸŒ é–‹å•Ÿç€è¦½å™¨ä¸¦å‰å¾€: http://localhost:5001")
        print("ğŸ“± æ‰‹æ©Ÿè¨ªå•è«‹ä½¿ç”¨: http://[æ‚¨çš„IP]:5001")
        print("ğŸ”´ æŒ‰ Ctrl+C åœæ­¢æœå‹™å™¨")
    except UnicodeEncodeError:
        print("Real-time Translation System Starting...")
        print("Open browser and go to: http://localhost:5001")
        print("Mobile access: http://[Your IP]:5001")
        print("Press Ctrl+C to stop server")
    
    app.run(debug=True, host='0.0.0.0', port=5001)